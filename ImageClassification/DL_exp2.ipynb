{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from dataloaders.FashionMnist import load_FashionMnist\n",
    "from tools.model_trainer import train_model\n",
    "from tools.model_tester import test_model\n",
    "from torchsummary import summary\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 60000\n",
      "test size: 10000\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\lxh_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg = edict({\n",
    "    'device':device,\n",
    "    'batch_size': 64,\n",
    "    'num_classes': 10,  # 分类类别\n",
    "    'lr': 0.01,  # 学习率\n",
    "    'epoch_size': 20  # 训练次数\n",
    "})\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_iter, _, test_iter = load_FashionMnist(batch_size=cfg.batch_size, transform=transform)\n",
    "print(f\"train size: {len(train_iter.dataset)}\")\n",
    "# print(f\"valid size: {len(valid_iter.dataset)}\")\n",
    "print(f\"test size: {len(test_iter.dataset)}\")\n",
    "for X, y in test_iter:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 不使用正则化的卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "Epoch 1/20\n",
      "937/937 [========================================] Train Loss: 0.4992, Train Accuracy: 0.8114, Valid Loss: 0.4258, Valid Accuracy: 0.8356, Cost Time 13.3510 sec\n",
      "Epoch 2/20\n",
      "937/937 [========================================] Train Loss: 0.3590, Train Accuracy: 0.8688, Valid Loss: 0.3562, Valid Accuracy: 0.8704, Cost Time 11.1327 sec\n",
      "Epoch 3/20\n",
      "937/937 [========================================] Train Loss: 0.3381, Train Accuracy: 0.8759, Valid Loss: 0.3667, Valid Accuracy: 0.8661, Cost Time 11.7559 sec\n",
      "Epoch 4/20\n",
      "937/937 [========================================] Train Loss: 0.3241, Train Accuracy: 0.8812, Valid Loss: 0.3733, Valid Accuracy: 0.8623, Cost Time 15.1042 sec\n",
      "Epoch 5/20\n",
      "937/937 [========================================] Train Loss: 0.3175, Train Accuracy: 0.8854, Valid Loss: 0.3766, Valid Accuracy: 0.8664, Cost Time 16.9977 sec\n",
      "Epoch 6/20\n",
      "937/937 [========================================] Train Loss: 0.3073, Train Accuracy: 0.8880, Valid Loss: 0.3646, Valid Accuracy: 0.8679, Cost Time 14.6738 sec\n",
      "Epoch 7/20\n",
      "937/937 [========================================] Train Loss: 0.3011, Train Accuracy: 0.8905, Valid Loss: 0.3829, Valid Accuracy: 0.8629, Cost Time 15.5696 sec\n",
      "Epoch 8/20\n",
      "937/937 [========================================] Train Loss: 0.3029, Train Accuracy: 0.8904, Valid Loss: 0.4097, Valid Accuracy: 0.8665, Cost Time 14.1999 sec\n",
      "Epoch 9/20\n",
      "937/937 [========================================] Train Loss: 0.3076, Train Accuracy: 0.8883, Valid Loss: 0.3413, Valid Accuracy: 0.8771, Cost Time 16.1780 sec\n",
      "Epoch 10/20\n",
      "937/937 [========================================] Train Loss: 0.2888, Train Accuracy: 0.8949, Valid Loss: 0.3449, Valid Accuracy: 0.8794, Cost Time 14.0384 sec\n",
      "Epoch 11/20\n",
      "937/937 [========================================] Train Loss: 0.2963, Train Accuracy: 0.8938, Valid Loss: 0.3420, Valid Accuracy: 0.8817, Cost Time 12.0220 sec\n",
      "Epoch 12/20\n",
      "937/937 [========================================] Train Loss: 0.2728, Train Accuracy: 0.9005, Valid Loss: 0.3561, Valid Accuracy: 0.8683, Cost Time 13.7817 sec\n",
      "Epoch 13/20\n",
      "937/937 [========================================] Train Loss: 0.2785, Train Accuracy: 0.9008, Valid Loss: 0.3411, Valid Accuracy: 0.8850, Cost Time 13.6076 sec\n",
      "Epoch 14/20\n",
      "937/937 [========================================] Train Loss: 0.2815, Train Accuracy: 0.8979, Valid Loss: 0.3562, Valid Accuracy: 0.8785, Cost Time 12.6940 sec\n",
      "Epoch 15/20\n",
      "937/937 [========================================] Train Loss: 0.2779, Train Accuracy: 0.8986, Valid Loss: 0.3787, Valid Accuracy: 0.8787, Cost Time 13.6268 sec\n",
      "Epoch 16/20\n",
      "937/937 [========================================] Train Loss: 0.2810, Train Accuracy: 0.8978, Valid Loss: 0.4423, Valid Accuracy: 0.8622, Cost Time 11.6433 sec\n",
      "Epoch 17/20\n",
      "937/937 [========================================] Train Loss: 0.3058, Train Accuracy: 0.8922, Valid Loss: 0.4384, Valid Accuracy: 0.8670, Cost Time 11.5413 sec\n",
      "Epoch 18/20\n",
      "937/937 [========================================] Train Loss: 0.2840, Train Accuracy: 0.8974, Valid Loss: 0.3561, Valid Accuracy: 0.8801, Cost Time 12.6880 sec\n",
      "Epoch 19/20\n",
      "937/937 [========================================] Train Loss: 0.2672, Train Accuracy: 0.9030, Valid Loss: 0.3836, Valid Accuracy: 0.8742, Cost Time 13.1113 sec\n",
      "Epoch 20/20\n",
      "937/937 [========================================] Train Loss: 0.2835, Train Accuracy: 0.8990, Valid Loss: 0.3974, Valid Accuracy: 0.8810, Cost Time 14.1795 sec\n",
      "Train result\n",
      "loss 0.2835\n",
      "final train Accuracy 0.8990\n",
      "final valid Accuracy 0.8810\n",
      "4411.0887 examples/sec on cuda\n",
      "13.5948 sec/epoch on cuda\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=0, bias=False), nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0, bias=False), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0, bias=False), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128*5*5, 120), nn.ReLU(),\n",
    "    nn.Linear(120, 84), nn.ReLU(),\n",
    "    nn.Linear(84, cfg.num_classes)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr)\n",
    "train_model(net, train_iter, test_iter, loss_fn, ['accuracy'], optimizer, num_epochs=cfg.epoch_size, device=device, use_tensorboard=True, print_log=True,comment='_DL_Exp2_without_normalization') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 对比正则化技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 使用L1正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "Epoch 1/20\n",
      "0/937 [               ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\lxh_torch\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [===============] Train Loss: 1.0921, Train Accuracy: 0.7128, Valid Loss: 0.5580, Valid Accuracy: 0.7894, Cost Time 25.2613 sec\n",
      "Epoch 2/20\n",
      "937/937 [===============] Train Loss: 0.8279, Train Accuracy: 0.8124, Valid Loss: 0.5397, Valid Accuracy: 0.8116, Cost Time 22.2559 sec\n",
      "Epoch 3/20\n",
      "937/937 [===============] Train Loss: 0.7806, Train Accuracy: 0.8218, Valid Loss: 0.4863, Valid Accuracy: 0.8201, Cost Time 19.1095 sec\n",
      "Epoch 4/20\n",
      "937/937 [===============] Train Loss: 0.7598, Train Accuracy: 0.8274, Valid Loss: 0.4796, Valid Accuracy: 0.8223, Cost Time 15.6250 sec\n",
      "Epoch 5/20\n",
      "937/937 [===============] Train Loss: 0.7571, Train Accuracy: 0.8307, Valid Loss: 0.5247, Valid Accuracy: 0.8115, Cost Time 16.5656 sec\n",
      "Epoch 6/20\n",
      "937/937 [===============] Train Loss: 0.7352, Train Accuracy: 0.8352, Valid Loss: 0.4941, Valid Accuracy: 0.8250, Cost Time 19.0371 sec\n",
      "Epoch 7/20\n",
      "937/937 [===============] Train Loss: 0.7413, Train Accuracy: 0.8317, Valid Loss: 0.4820, Valid Accuracy: 0.8240, Cost Time 17.9121 sec\n",
      "Epoch 8/20\n",
      "937/937 [===============] Train Loss: 0.7277, Train Accuracy: 0.8353, Valid Loss: 0.4676, Valid Accuracy: 0.8275, Cost Time 17.1447 sec\n",
      "Epoch 9/20\n",
      "937/937 [===============] Train Loss: 0.7327, Train Accuracy: 0.8327, Valid Loss: 0.4612, Valid Accuracy: 0.8293, Cost Time 20.3834 sec\n",
      "Epoch 10/20\n",
      "937/937 [===============] Train Loss: 0.7318, Train Accuracy: 0.8349, Valid Loss: 0.5094, Valid Accuracy: 0.8181, Cost Time 19.3123 sec\n",
      "Epoch 11/20\n",
      "937/937 [===============] Train Loss: 0.7290, Train Accuracy: 0.8324, Valid Loss: 0.4783, Valid Accuracy: 0.8281, Cost Time 17.2983 sec\n",
      "Epoch 12/20\n",
      "937/937 [===============] Train Loss: 0.7316, Train Accuracy: 0.8355, Valid Loss: 0.4919, Valid Accuracy: 0.8213, Cost Time 16.4648 sec\n",
      "Epoch 13/20\n",
      "937/937 [===============] Train Loss: 0.7316, Train Accuracy: 0.8330, Valid Loss: 0.4657, Valid Accuracy: 0.8321, Cost Time 16.9961 sec\n",
      "Epoch 14/20\n",
      "937/937 [===============] Train Loss: 0.7213, Train Accuracy: 0.8335, Valid Loss: 0.4753, Valid Accuracy: 0.8293, Cost Time 16.5100 sec\n",
      "Epoch 15/20\n",
      "937/937 [===============] Train Loss: 0.7340, Train Accuracy: 0.8345, Valid Loss: 0.4515, Valid Accuracy: 0.8382, Cost Time 16.0580 sec\n",
      "Epoch 16/20\n",
      "937/937 [===============] Train Loss: 0.7290, Train Accuracy: 0.8355, Valid Loss: 0.5221, Valid Accuracy: 0.8069, Cost Time 17.6543 sec\n",
      "Epoch 17/20\n",
      "937/937 [===============] Train Loss: 0.7373, Train Accuracy: 0.8354, Valid Loss: 0.4587, Valid Accuracy: 0.8358, Cost Time 20.5465 sec\n",
      "Epoch 18/20\n",
      "937/937 [===============] Train Loss: 0.7188, Train Accuracy: 0.8367, Valid Loss: 0.5279, Valid Accuracy: 0.8073, Cost Time 17.8928 sec\n",
      "Epoch 19/20\n",
      "937/937 [===============] Train Loss: 0.7251, Train Accuracy: 0.8356, Valid Loss: 0.4719, Valid Accuracy: 0.8296, Cost Time 17.1277 sec\n",
      "Epoch 20/20\n",
      "937/937 [===============] Train Loss: 0.7215, Train Accuracy: 0.8357, Valid Loss: 0.4840, Valid Accuracy: 0.8274, Cost Time 18.8257 sec\n",
      "Train result\n",
      "loss 0.7215\n",
      "final train Accuracy 0.8357\n",
      "final valid Accuracy 0.8274\n",
      "3259.2972 examples/sec on cuda\n",
      "18.3991 sec/epoch on cuda\n"
     ]
    }
   ],
   "source": [
    "from tools.model_trainer import train_batch_L1\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
    "    nn.Linear(120, 84), nn.ReLU(),\n",
    "    nn.Linear(84, cfg.num_classes)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr, weight_decay=0.001) # L2正则化\n",
    "train_model(net, train_iter, test_iter, loss_fn, ['accuracy'], optimizer, num_epochs=cfg.epoch_size, device=device, train_func=train_batch_L1, use_tensorboard=True, print_log=True,comment='_DL_Exp2_with_L1_normalization') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 使用L2正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "Epoch 1/20\n",
      "937/937 [========================================] Train Loss: 0.6601, Train Accuracy: 0.7496, Valid Loss: 0.5170, Valid Accuracy: 0.8025, Cost Time 13.3259 sec\n",
      "Epoch 2/20\n",
      "937/937 [========================================] Train Loss: 0.5167, Train Accuracy: 0.8127, Valid Loss: 0.4991, Valid Accuracy: 0.8115, Cost Time 11.6148 sec\n",
      "Epoch 3/20\n",
      "937/937 [========================================] Train Loss: 0.4957, Train Accuracy: 0.8214, Valid Loss: 0.4950, Valid Accuracy: 0.8226, Cost Time 11.2439 sec\n",
      "Epoch 4/20\n",
      "937/937 [========================================] Train Loss: 0.4919, Train Accuracy: 0.8228, Valid Loss: 0.5294, Valid Accuracy: 0.8089, Cost Time 11.1479 sec\n",
      "Epoch 5/20\n",
      "937/937 [========================================] Train Loss: 0.4827, Train Accuracy: 0.8257, Valid Loss: 0.4941, Valid Accuracy: 0.8198, Cost Time 11.9004 sec\n",
      "Epoch 6/20\n",
      "937/937 [========================================] Train Loss: 0.4789, Train Accuracy: 0.8266, Valid Loss: 0.5047, Valid Accuracy: 0.8072, Cost Time 11.6626 sec\n",
      "Epoch 7/20\n",
      "937/937 [========================================] Train Loss: 0.4817, Train Accuracy: 0.8275, Valid Loss: 0.4516, Valid Accuracy: 0.8335, Cost Time 11.7073 sec\n",
      "Epoch 8/20\n",
      "937/937 [========================================] Train Loss: 0.4779, Train Accuracy: 0.8280, Valid Loss: 0.4739, Valid Accuracy: 0.8252, Cost Time 12.2348 sec\n",
      "Epoch 9/20\n",
      "937/937 [========================================] Train Loss: 0.4721, Train Accuracy: 0.8302, Valid Loss: 0.5399, Valid Accuracy: 0.8027, Cost Time 12.3716 sec\n",
      "Epoch 10/20\n",
      "937/937 [========================================] Train Loss: 0.4719, Train Accuracy: 0.8304, Valid Loss: 0.4559, Valid Accuracy: 0.8366, Cost Time 12.0180 sec\n",
      "Epoch 11/20\n",
      "937/937 [========================================] Train Loss: 0.4660, Train Accuracy: 0.8328, Valid Loss: 0.5146, Valid Accuracy: 0.8126, Cost Time 11.4010 sec\n",
      "Epoch 12/20\n",
      "937/937 [========================================] Train Loss: 0.4728, Train Accuracy: 0.8304, Valid Loss: 0.4989, Valid Accuracy: 0.8205, Cost Time 12.2924 sec\n",
      "Epoch 13/20\n",
      "937/937 [========================================] Train Loss: 0.4704, Train Accuracy: 0.8315, Valid Loss: 0.4763, Valid Accuracy: 0.8283, Cost Time 11.7791 sec\n",
      "Epoch 14/20\n",
      "937/937 [========================================] Train Loss: 0.4699, Train Accuracy: 0.8306, Valid Loss: 0.5109, Valid Accuracy: 0.8123, Cost Time 11.5161 sec\n",
      "Epoch 15/20\n",
      "937/937 [========================================] Train Loss: 0.4686, Train Accuracy: 0.8303, Valid Loss: 0.4828, Valid Accuracy: 0.8150, Cost Time 11.2665 sec\n",
      "Epoch 16/20\n",
      "937/937 [========================================] Train Loss: 0.4671, Train Accuracy: 0.8336, Valid Loss: 0.4686, Valid Accuracy: 0.8304, Cost Time 11.3786 sec\n",
      "Epoch 17/20\n",
      "937/937 [========================================] Train Loss: 0.4708, Train Accuracy: 0.8300, Valid Loss: 0.4741, Valid Accuracy: 0.8270, Cost Time 12.1931 sec\n",
      "Epoch 18/20\n",
      "937/937 [========================================] Train Loss: 0.4712, Train Accuracy: 0.8312, Valid Loss: 0.4837, Valid Accuracy: 0.8235, Cost Time 12.1689 sec\n",
      "Epoch 19/20\n",
      "937/937 [========================================] Train Loss: 0.4704, Train Accuracy: 0.8311, Valid Loss: 0.5003, Valid Accuracy: 0.8201, Cost Time 12.7857 sec\n",
      "Epoch 20/20\n",
      "937/937 [========================================] Train Loss: 0.4722, Train Accuracy: 0.8289, Valid Loss: 0.4579, Valid Accuracy: 0.8303, Cost Time 14.5349 sec\n",
      "Train result\n",
      "loss 0.4722\n",
      "final train Accuracy 0.8289\n",
      "final valid Accuracy 0.8303\n",
      "4986.0428 examples/sec on cuda\n",
      "12.0272 sec/epoch on cuda\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
    "    nn.Linear(120, 84), nn.ReLU(),\n",
    "    nn.Linear(84, cfg.num_classes)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr, weight_decay=0.001) # L2正则化\n",
    "train_model(net, train_iter, test_iter, loss_fn, ['accuracy'], optimizer, num_epochs=cfg.epoch_size, device=device, use_tensorboard=True, print_log=True,comment='_DL_Exp2_with_L2_normalization') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 使用Dropout正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "Epoch 1/20\n",
      "937/937 [========================================] Train Loss: 0.7863, Train Accuracy: 0.7073, Valid Loss: 0.5043, Valid Accuracy: 0.7973, Cost Time 14.1354 sec\n",
      "Epoch 2/20\n",
      "937/937 [========================================] Train Loss: 0.6276, Train Accuracy: 0.7825, Valid Loss: 0.4826, Valid Accuracy: 0.8348, Cost Time 12.5853 sec\n",
      "Epoch 3/20\n",
      "937/937 [========================================] Train Loss: 0.6002, Train Accuracy: 0.7972, Valid Loss: 0.5037, Valid Accuracy: 0.8261, Cost Time 12.1580 sec\n",
      "Epoch 4/20\n",
      "937/937 [========================================] Train Loss: 0.5893, Train Accuracy: 0.8003, Valid Loss: 0.4675, Valid Accuracy: 0.8439, Cost Time 11.0579 sec\n",
      "Epoch 5/20\n",
      "937/937 [========================================] Train Loss: 0.5976, Train Accuracy: 0.8011, Valid Loss: 0.4450, Valid Accuracy: 0.8396, Cost Time 10.3042 sec\n",
      "Epoch 6/20\n",
      "937/937 [========================================] Train Loss: 0.5817, Train Accuracy: 0.8059, Valid Loss: 0.4990, Valid Accuracy: 0.8288, Cost Time 10.5443 sec\n",
      "Epoch 7/20\n",
      "937/937 [========================================] Train Loss: 0.5709, Train Accuracy: 0.8112, Valid Loss: 0.4769, Valid Accuracy: 0.8375, Cost Time 10.5867 sec\n",
      "Epoch 8/20\n",
      "937/937 [========================================] Train Loss: 0.5811, Train Accuracy: 0.8087, Valid Loss: 0.4456, Valid Accuracy: 0.8382, Cost Time 10.7829 sec\n",
      "Epoch 9/20\n",
      "937/937 [========================================] Train Loss: 0.5917, Train Accuracy: 0.8055, Valid Loss: 0.5309, Valid Accuracy: 0.8248, Cost Time 11.1156 sec\n",
      "Epoch 10/20\n",
      "937/937 [========================================] Train Loss: 0.5765, Train Accuracy: 0.8102, Valid Loss: 0.4786, Valid Accuracy: 0.8383, Cost Time 11.5097 sec\n",
      "Epoch 11/20\n",
      "937/937 [========================================] Train Loss: 0.5872, Train Accuracy: 0.8058, Valid Loss: 0.4808, Valid Accuracy: 0.8261, Cost Time 11.4359 sec\n",
      "Epoch 12/20\n",
      "937/937 [========================================] Train Loss: 0.6031, Train Accuracy: 0.8009, Valid Loss: 0.5057, Valid Accuracy: 0.8248, Cost Time 10.6918 sec\n",
      "Epoch 13/20\n",
      "937/937 [========================================] Train Loss: 0.5837, Train Accuracy: 0.8106, Valid Loss: 0.4476, Valid Accuracy: 0.8409, Cost Time 11.1849 sec\n",
      "Epoch 14/20\n",
      "937/937 [========================================] Train Loss: 0.5701, Train Accuracy: 0.8112, Valid Loss: 0.4581, Valid Accuracy: 0.8382, Cost Time 10.9802 sec\n",
      "Epoch 15/20\n",
      "937/937 [========================================] Train Loss: 0.5852, Train Accuracy: 0.8087, Valid Loss: 0.4653, Valid Accuracy: 0.8342, Cost Time 10.9534 sec\n",
      "Epoch 16/20\n",
      "937/937 [========================================] Train Loss: 0.5925, Train Accuracy: 0.8053, Valid Loss: 0.4831, Valid Accuracy: 0.8405, Cost Time 10.8275 sec\n",
      "Epoch 17/20\n",
      "937/937 [========================================] Train Loss: 0.5838, Train Accuracy: 0.8074, Valid Loss: 0.4919, Valid Accuracy: 0.8243, Cost Time 11.0422 sec\n",
      "Epoch 18/20\n",
      "937/937 [========================================] Train Loss: 0.6073, Train Accuracy: 0.7999, Valid Loss: 0.4709, Valid Accuracy: 0.8244, Cost Time 10.7596 sec\n",
      "Epoch 19/20\n",
      "937/937 [========================================] Train Loss: 0.5867, Train Accuracy: 0.8060, Valid Loss: 0.4945, Valid Accuracy: 0.8343, Cost Time 10.1746 sec\n",
      "Epoch 20/20\n",
      "937/937 [========================================] Train Loss: 0.6312, Train Accuracy: 0.7947, Valid Loss: 0.4642, Valid Accuracy: 0.8350, Cost Time 10.7127 sec\n",
      "Train result\n",
      "loss 0.6312\n",
      "final train Accuracy 0.7947\n",
      "final valid Accuracy 0.8350\n",
      "5365.2348 examples/sec on cuda\n",
      "11.1771 sec/epoch on cuda\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(120, 84), nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(84, cfg.num_classes)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr) \n",
    "train_model(net, train_iter, test_iter, loss_fn, ['accuracy'], optimizer, num_epochs=cfg.epoch_size, device=device, use_tensorboard=True, print_log=True,comment='_DL_Exp2_with_Dropout') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 使用BN正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "    nn.BatchNorm2d(6), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.BatchNorm2d(6), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(120, 84), nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(84, cfg.num_classes)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr) \n",
    "train_model(net, train_iter, test_iter, loss_fn, ['accuracy'], optimizer, num_epochs=cfg.epoch_size, device=device, use_tensorboard=True, print_log=True,comment='_DL_Exp2_with_BN') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 使用Layer Normalization正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              ReLU-2            [-1, 6, 28, 28]               0\n",
      "         MaxPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-6             [-1, 16, 5, 5]               0\n",
      "           Flatten-7                  [-1, 400]               0\n",
      "            Linear-8                  [-1, 120]          48,120\n",
      "              ReLU-9                  [-1, 120]               0\n",
      "           Linear-10                   [-1, 84]          10,164\n",
      "             ReLU-11                   [-1, 84]               0\n",
      "           Linear-12                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "Epoch 1/20\n",
      "937/937 [===============] Train Loss: 1.0180, Train Accuracy: 0.5984, Valid Loss: 0.5627, Valid Accuracy: 0.8046, Cost Time 15.6610 sec\n",
      "Epoch 2/20\n",
      "937/937 [===============] Train Loss: 0.7480, Train Accuracy: 0.7194, Valid Loss: 0.5063, Valid Accuracy: 0.7988, Cost Time 13.5620 sec\n",
      "Epoch 3/20\n",
      "937/937 [===============] Train Loss: 0.6704, Train Accuracy: 0.7571, Valid Loss: 0.4864, Valid Accuracy: 0.8183, Cost Time 17.8880 sec\n",
      "Epoch 4/20\n",
      "937/937 [===============] Train Loss: 0.6263, Train Accuracy: 0.7769, Valid Loss: 0.5092, Valid Accuracy: 0.7829, Cost Time 15.9799 sec\n",
      "Epoch 5/20\n",
      "937/937 [===============] Train Loss: 0.6016, Train Accuracy: 0.7861, Valid Loss: 0.4777, Valid Accuracy: 0.8392, Cost Time 19.4339 sec\n",
      "Epoch 6/20\n",
      "937/937 [===============] Train Loss: 0.5832, Train Accuracy: 0.7958, Valid Loss: 0.4512, Valid Accuracy: 0.8370, Cost Time 20.6814 sec\n",
      "Epoch 7/20\n",
      "937/937 [===============] Train Loss: 0.5712, Train Accuracy: 0.8004, Valid Loss: 0.4592, Valid Accuracy: 0.8481, Cost Time 20.6163 sec\n",
      "Epoch 8/20\n",
      "937/937 [===============] Train Loss: 0.5536, Train Accuracy: 0.8089, Valid Loss: 0.4399, Valid Accuracy: 0.8440, Cost Time 22.8050 sec\n",
      "Epoch 9/20\n",
      "937/937 [===============] Train Loss: 0.5414, Train Accuracy: 0.8082, Valid Loss: 0.4629, Valid Accuracy: 0.8252, Cost Time 19.0508 sec\n",
      "Epoch 10/20\n",
      "937/937 [===============] Train Loss: 0.5374, Train Accuracy: 0.8120, Valid Loss: 0.4431, Valid Accuracy: 0.8432, Cost Time 24.7891 sec\n",
      "Epoch 11/20\n",
      "937/937 [===============] Train Loss: 0.5349, Train Accuracy: 0.8143, Valid Loss: 0.4228, Valid Accuracy: 0.8489, Cost Time 19.5830 sec\n",
      "Epoch 12/20\n",
      "937/937 [===============] Train Loss: 0.5417, Train Accuracy: 0.8159, Valid Loss: 0.4373, Valid Accuracy: 0.8506, Cost Time 16.2475 sec\n",
      "Epoch 13/20\n",
      "937/937 [===============] Train Loss: 0.5330, Train Accuracy: 0.8155, Valid Loss: 0.4653, Valid Accuracy: 0.8454, Cost Time 15.8764 sec\n",
      "Epoch 14/20\n",
      "937/937 [===============] Train Loss: 0.5124, Train Accuracy: 0.8237, Valid Loss: 0.4511, Valid Accuracy: 0.8333, Cost Time 18.8820 sec\n",
      "Epoch 15/20\n",
      "937/937 [===============] Train Loss: 0.4992, Train Accuracy: 0.8255, Valid Loss: 0.4177, Valid Accuracy: 0.8575, Cost Time 18.6818 sec\n",
      "Epoch 16/20\n",
      "937/937 [===============] Train Loss: 0.5052, Train Accuracy: 0.8245, Valid Loss: 0.4756, Valid Accuracy: 0.8447, Cost Time 20.3459 sec\n",
      "Epoch 17/20\n",
      "937/937 [===============] Train Loss: 0.5000, Train Accuracy: 0.8267, Valid Loss: 0.4300, Valid Accuracy: 0.8529, Cost Time 21.2448 sec\n",
      "Epoch 18/20\n",
      "937/937 [===============] Train Loss: 0.4997, Train Accuracy: 0.8287, Valid Loss: 0.4466, Valid Accuracy: 0.8388, Cost Time 19.5237 sec\n",
      "Epoch 19/20\n",
      "937/937 [===============] Train Loss: 0.4834, Train Accuracy: 0.8324, Valid Loss: 0.4246, Valid Accuracy: 0.8475, Cost Time 23.1078 sec\n",
      "Epoch 20/20\n",
      "937/937 [===============] Train Loss: 0.4954, Train Accuracy: 0.8290, Valid Loss: 0.4547, Valid Accuracy: 0.8394, Cost Time 21.6033 sec\n",
      "Train result\n",
      "loss 0.4954\n",
      "final train Accuracy 0.8290\n",
      "final valid Accuracy 0.8394\n",
      "3110.6675 examples/sec on cuda\n",
      "19.2782 sec/epoch on cuda\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "    nn.LayerNorm((6, 28, 28)), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.LayerNorm((16, 10, 10)), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(120, 84), nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(84, cfg.num_classes)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr) \n",
    "train_model(net, train_iter, test_iter, loss_fn, ['accuracy'], optimizer, num_epochs=cfg.epoch_size, device=device, use_tensorboard=True, print_log=True,comment='_DL_Exp2_with_LN') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 SELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda\n",
      "Epoch 1/20\n",
      "107/937 [=              ]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_42548/2012468932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_tensorboard\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_DL_Exp2_with_SELU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\dell\\Desktop\\lxh-DL\\tools\\model_trainer.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(net, train_iter, valid_iter, loss_fn, metrics, optimizer, num_epochs, device, train_func, use_animator, use_tensorboard, print_log, log_dir, comment, len_progress)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m#         raise NotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dell\\Desktop\\lxh-DL\\tools\\model_trainer.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(net, train_iter, valid_iter, loss_fn, metrics, optimizer, num_epochs, device, train_func, animator, writer, print_log, len_progress)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             loss_sum, metrics_sum = train_func(net, features, labels,\n\u001b[1;32m--> 124\u001b[1;33m                                  loss_fn, metrics, optimizer, device)\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmetrics_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dell\\Desktop\\lxh-DL\\tools\\model_trainer.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(net, X, y, loss_fn, metrics, optimizer, device)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mtrain_metrics_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mtrain_metrics_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_loss_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_metrics_sum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dell\\Desktop\\lxh-DL\\tools\\metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y_pred, y_true, method)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dell\\Desktop\\lxh-DL\\tools\\metrics.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(y_pred, y_true, method)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mcmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sum'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.SELU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.SELU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.SELU(),\n",
    "    nn.Linear(120, 84), nn.SELU(),\n",
    "    nn.Linear(84, cfg.num_classes)\n",
    ")\n",
    "\n",
    "# 默认是Kaiming初始化\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=cfg.lr)\n",
    "train_model(net, train_iter, test_iter, loss_fn, ['accuracy'], optimizer, num_epochs=cfg.epoch_size, device=device, use_tensorboard=True, print_log=True,comment='_DL_Exp2_with_SELU') "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59b6f011735db47521bb582faba6888a8626bd927f083c4402b4350276843300"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('lxh_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
